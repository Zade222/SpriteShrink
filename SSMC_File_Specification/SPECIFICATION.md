# SpriteShrink Multi-Cart (.ssmc) File Specification

## 1. Overview

This document specifies the binary layout for the "SpriteShrink Multi-Cart" (SSMC) deduplication archive format. The format is designed to be compact, efficient to parse, and scalable, allowing for quick querying of metadata without reading the entire file. It uses individually compressed chunks and a shared dictionary to balance high compression ratios with fast random access.

The file is composed of five distinct, sequential sections:

* **Header:** A fixed-size section at the beginning of the file containing critical metadata and offsets to the other sections.
* **File Manifest:** A variable-size section containing the metadata required to reconstruct all original files.
* **Compression Dictionary:** A variable-size section containing the shared dictionary used to compress every chunk in the Data Blob.
* **Chunk Index:** A variable-size section that maps each unique data chunk's hash to its location and compressed size within the Data Blob.
* **Data Blob:** A variable-size section containing the individually compressed binary data of all unique, deduplicated chunks.

### Logical Layout

```
+--------------------------------+
|         Header (Fixed)         |
+--------------------------------+
|    File Manifest (Variable)    |
+--------------------------------+
| Compression Dictionary (Var)   |
+--------------------------------+
|     Chunk Index (Variable)     |
+--------------------------------+
|      Data Blob (Variable)      |
+--------------------------------+
```

## 2. Section Details

### 2.1. Header (Fixed Size: 80 Bytes)

The header provides a quick summary of the archive's contents and the location of its primary data structures. It is always 80 bytes long.

| Offset (Bytes) | Length (Bytes) | Data Type | Description |
| :--- | :--- | :--- | :--- |
| 0 | 8 | `[u8; 8]` | **Magic Number:** A constant value to identify the file type. Recommended: `b"SSMC_V1_"` |
| 8 | 4 | `u32` | **Format Version:** The version of the file format (e.g., `0x00010000` for v1.0). |
| 12 | 4 | `u32` | **File Count:** The total number of files stored in the archive. |
| 16 | 2 | `u16` | **Compression Algorithm:** An enum representing the algorithm used. E.g., `98=Zstd`. |
| 18 | 1 | `u16` | **Hash Type:** A numerical id representing the hash type used. E.g., 1 = xxhash3_64, 2 = xxhash3_128. |
| 19 | 5 | `[u8; 5]` | **Padding:** Reserved for alignment or future information. Must be all zeros. |
| 24 | 8 | `u64` | **Manifest Offset:** The absolute byte offset where the File Manifest section begins. |
| 32 | 8 | `u64` | **Manifest Length:** The total length of the File Manifest section in bytes. |
| 40 | 8 | `u64` | **Dictionary Offset:** The absolute byte offset where the Compression Dictionary begins. |
| 48 | 8 | `u64` | **Dictionary Length:** The total length of the Compression Dictionary in bytes. |
| 56 | 8 | `u64` | **Chunk Index Offset:** The absolute byte offset where the Chunk Index section begins. |
| 64 | 8 | `u64` | **Chunk Index Length:** The total length of the Chunk Index section in bytes. |
| 72 | 8 | `u64` | **Data Blob Offset:** The absolute byte offset where the Data Blob section begins. |

### 2.2. File Manifest (Variable Size)

This section contains all the information needed to reconstruct the original files' directory structure and content. It is a single data block created by serializing a `Vec<FileManifestParent>` using Bincode.

The corresponding Rust structures would be:

```rust
// #[derive(Clone, Deserialize, Serialize)]
pub struct FileManifestParent<H> {
    pub filename:       String,
    pub chunk_count:    u64,
    pub chunk_metadata: Vec<SSAChunkMeta<H>>,
}

// #[derive(Clone, Deserialize, Serialize)]
pub struct SSAChunkMeta<H> {
    pub hash: H,
    pub offset: u64,
    pub length: u32, // Uncompressed length
}
```

**Note:** The `length` field in `SSAChunkMeta` represents the chunk's original, *uncompressed* size.

### 2.3. Compression Dictionary (Variable Size)

This section contains the raw binary data of the compression dictionary (e.g., generated by zstd). This dictionary must be loaded and used for any compression or decompression operation on the chunks in the Data Blob.

### 2.4. Chunk Index (Variable Size)

This section acts as the master lookup table for finding the data of any given chunk. It is a single data block created by serializing a `HashMap<u64, ChunkLocation>` using Bincode.

* **Key (`u64 or u128`):** The `xxhash3_64` or `xxhash3_128` hash of a unique data chunk.
* **Value (`ChunkLocation`):** A struct containing the location and compressed size of the chunk.

The `ChunkLocation` struct:

```rust
// #[derive(Serialize, Deserialize)]
pub struct ChunkLocation {
    pub offset: u64,
    pub compressed_length: u32,
}
```

### 2.5. Data Blob (Variable Size)

This is the final section of the file. It is a single, contiguous block of binary data containing all unique chunks, *individually compressed*, and concatenated one after another. To read a chunk, one must use its `offset` and `compressed_length` from the Chunk Index to read the correct block of bytes, then decompress it using the shared Compression Dictionary.

## 3. Example Read Operations

### To List All Files in the Archive:

1.  Read the 80-byte **Header**.
2.  From the header, get the `Manifest Offset` and `Manifest Length`.
3.  Seek to the `Manifest Offset` in the file.
4.  Read `Manifest Length` bytes into a buffer.
5.  Deserialize the buffer using Bincode into a `Vec<FileManifestParent>`.
6.  Iterate through the resulting vector and print the `filename` from each `FileManifestParent`.

### To Extract a Specific File ("example.txt"):

1.  Read the **Header**.
2.  Load the **File Manifest** into memory (using its offset and length from the header).
3.  Load the **Compression Dictionary** into memory (using its offset and length from the header).
4.  Load the **Chunk Index** into memory and deserialize it into a `HashMap<u64, ChunkLocation>`.
5.  Find the `FileManifestParent` where `filename == "example.rom"`.
6.  Create an empty output file "example.txt".
7.  For each `SSAChunkMeta` in the file's `chunks` vector:
    a. Get the chunk `hash`, `offset` (in original file), and `length` (uncompressed).
    b. Look up the `hash` in the Chunk Index map to get its `ChunkLocation`.
    c. Seek the archive file to `Header.DataBlobOffset` + `ChunkLocation.offset`.
    d. Read `ChunkLocation.compressed_length` bytes into a compressed buffer.
    e. Decompress the buffer using the loaded dictionary into a buffer of size `length`.
    f. Seek the output file to `offset`.
    g. Write the decompressed chunk data to the output file.
